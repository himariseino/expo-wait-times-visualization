name: Scrape Wait Times and Run ETL

on:
  schedule:
    - cron: '0 23 * * *'  # JST 08:00
    - cron: '0 0 * * *'   # JST 09:00
    - cron: '0 1 * * *'   # JST 10:00
    - cron: '0 2 * * *'   # JST 11:00
    - cron: '0 3 * * *'   # JST 12:00
    - cron: '0 4 * * *'   # JST 13:00
    - cron: '0 5 * * *'   # JST 14:00
    - cron: '0 6 * * *'   # JST 15:00
    - cron: '0 7 * * *'   # JST 16:00
    - cron: '0 8 * * *'   # JST 17:00
    - cron: '0 9 * * *'   # JST 18:00
    - cron: '0 10 * * *'  # JST 19:00
    - cron: '0 11 * * *'  # JST 20:00
    - cron: '0 12 * * *'  # JST 21:00
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        run: pip install uv

      - name: Install dependencies using uv
        run: uv pip install --system --project .

      - name: Run scraper
        run: uv run scripts/fetch_data.py

      - name: Run ETL
        run: uv run etl/etl.py

      - name: Commit & push CSV and DB file
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add wait_times.csv data/db/wait_times.db
          git commit -m "Update wait times data and DB" || echo "No changes to commit"
          git push